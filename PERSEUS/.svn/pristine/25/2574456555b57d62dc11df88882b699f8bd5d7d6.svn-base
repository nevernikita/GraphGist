################################################################################################################################################
*                                                     Documentation for                                                                        *
*                                                       OPAvion+ v0.1                                                                          *
################################################################################################################################################
*                                         contact: Danai Koutra, danai@cs.cmu.edu                                                              *
################################################################################################################################################






################################################################################################################################################
0) CONTENTS
################################################################################################################################################
  1: Description of the package and its capabilities
  2: Installation for Linux and MacOSX
    2a: Automatic
    2b: Manual
  3: Testing the installation
  4: Citations


################################################################################################################################################
1) DESCRIPTION: 
################################################################################################################################################

OPAvion+ performs several data mining tasks on a given graph (csv or sqlite3 -
TBD):
(1) pegasus
(2) netRay for distribution and correlation plots
(3) VoG
(4) Gephi
(5) Apolo
(6) ...
and presents all the plots in an applet.


Its components are:
(1) Pegasus, framework that provides scalable graph algorithms built on top of
Hadoop for billion-node graphs that don't fit in memory. 

(2) NetRay

(3) VoG

(4) Gephi

(5) Apolo, software for graph visualization. In this project it is used to vi-
sualize the vicinities of several nodes of interest.

(6) ...

################################################################################################################################################
2) INSTALLATION
################################################################################################################################################

The OPAvion+ package includes hadoop.

(a) AUTOMATIC INSTALLATION:  
   
      cd <OPAvion+ folder>
      chmod +x setEnv.sh
      ./setEnv.sh

   !! Note: Checked distributions: MacOSX and Ubuntu
        (1) MacOSX requirements:
	    * java: version 1.6.0_31
	    * sqlite3: version 3.6.12
	    * hadoop: 0.20.203.0 (installed in the <OPAvion+ folder>)
        (2) Linux requirements:
	    * java: java-6-openjdk
	    * sqlite3: version 3.6.22
	    * hadoop: 0.20.203.0 (comes in the <OPAvion+ folder>)

   !! Troubleshooting for Linux:
      If 'which java' gives /usr/bin/java as output, then do '
          'sudo update-alternatives --config java'

       If 'which hadoop' is empty, try re-running the command 
          'source ~/.bashrc'
       Now the command 'which hadoop' should return ${HADOOP_HOME}/bin/hadoop.  

(b) MANUAL INSTALLATION for MacOSX and Linux

	#######################################################
        * Step 0: MacOSX users should first do the following: *
	#######################################################

		(i) In terminal type: /usr/libexec/java_home
			This is your java_home: e.g. /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home
		(ii) Edit the file <OPAvion+ folder>/hadoop-0.20.203.0/conf/hadoop-env.sh 
			and uncomment the line that is setting JAVA_HOME:
			export JAVA_HOME=result/of/step/a/BEFORE/*.jdk                  
			e.g.export JAVA_HOME= /System/Library/Java/JavaVirtualMachines/1.6.0.jdk
		(iii) Edit the file <OPAvion+ folder>/hadoop-0.20.203.0/bin/hadoop
			Replace
				JAVA=$JAVA_HOME/bin/java
			by 
				JAVA_HOME=$JAVA_HOME/result/of/step/a/AFTER/*.jdk
			e.g., JAVA=$JAVA_HOME/Contents/Home
		(iv) type 'which hadoop'
			if empty, do:
				cd $HADOOP_HOME/bin/hadoop
				chmod u+x bin/hadoop

	#########################################################
	* Step 1: Add the following lines in the ~/.bashrc file *
	#########################################################

		export JAVA_HOME=YOUR/PATH/TO/JAVA
		export HADOOP_HOME=/YOUR/HADOOP/DIRECTORY
		export PATH=${HADOOP_HOME}/bin:${PATH}
		export HADOOP_VERSION=YOUR_HADOOP_VERSION

		Save ~/.bashrc and type in terminal:
     
			source ~/.bashrc
	

		e.g. YOUR/PATH/TO/JAVA : /usr/lib/jvm/java-6-sun-1.6.0.26
		     YOUR/HADOOP/DIRECTORY : /home/beatrix/<OPAvion+ folder>/hadoop-0.20.203.0
		     YOUR_HADOOP_VERSION : 0.20.203.0 (if you are using the hadoop version included in the package)


	#########################################################
	* Step 2: Check if hadoop is accessible from everywhere *
	#########################################################

		Type in terminal 'which hadoop'
		if empty, do: 
			source ~/.bashrc
			cd $HADOOP_HOME/bin/hadoop
			chmod u+x bin/hadoop

		** If running on UNIX: **
		Edit the file <OPAvion+ folder>/hadoop-0.20.203.0/conf/hadoop-env.sh 
		and uncomment the line that is setting JAVA_HOME:
			export JAVA_HOME=YOUR/PATH/TO/JAVA

		e.g. export JAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.26 or
	   	     export JAVA_HOME=/usr/lib/jvm/java-6-openjdk/jre/



################################################################################################################################################
2) TESTING THE INSTALLATION
################################################################################################################################################

To test that hadoop was installed properly in single-node mode, try running the wordcount code included in the hadoop distribution. To do so, type:

make test_hadoop

This script should produce a file part-00* in hadoop-0.20.203.0/out/ with all the words that appear in the current README file and their count.


################################################################################################################################################
              C I T A T I O N S
################################################################################################################################################

[1] Main Contact: U Kang (ukang@cs.cmu.edu) 
PEGASUS: A Peta-Scale Graph Mining System - Implementation and Observations.
Kang, U and Tsourakakis, C.E and Faloutsos, C.
IEEE International Conference On Data Mining, 2009.

PEGASUS: Mining Peta-Scale Graphs.
Kang, U and Tsourakakis,C.E and Faloutsos,C.
Knowledge and Information Systems, 2010.

[2] NetRay...

[3] VoG

[4] Main Contact: Polo Chau (dchau@cs.cmu.edu)
Apolo: Making Sense of Large Network Data by Combining Rich User Interaction and Machine Learning. 
Duen Horng (Polo) Chau, Aniket Kittur, Jason I. Hong, Christos Faloutsos. 
ACM Conference on Human Factors in Computing Systems (CHI) 2011. May 7-12, 2011. 
Vancouver, BC, Canada.


